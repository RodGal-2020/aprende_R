---
title: "Siguiente paso"
subtitle: "Aprende R"
author: "Xopre Rodr铆guez Gallego"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
codification: "UTF-8"
output:
  # Cambia los comentarios si quieres usar otro formato
  pdf_document
  # rmdformats::material:
  #   highlight: kate
  # ioslides_presentation:
  #   widescreen: true # Wider form factor
  #   transition: slower # default
  #   notes: true # Show notes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Opciones

## Opciones

Tenemos como opciones las siguientes:

- algor铆tmica
- estad铆stica
- *machine learning*

# Algor铆tmica

## Algor铆tmica

Lo que originalmente estaba en el proyecto, e inclu铆a las siguientes opciones:

- *Algoritmo de bisecci贸n*.
- *Algoritmo de Newton*.

## Ejemplo

Implementaci贸n del algoritmo de Newton sobre el conjunto de datos iris para predecir la longitud del s茅palo.

```{r}
# Cargar los datos
Data = iris

# Variable dependiente (Sepal.Length) y variables independientes
y = Data$Sepal.Length
X = as.matrix(cbind(1, Data$Sepal.Width, Data$Petal.Length, Data$Petal.Width)) # Agregar columna de unos para el intercepto
```

## Ejemplo

```{r}
# Funci贸n para calcular la matriz Hessiana
hessian <- function(X, beta) {
  return(t(X) %*% X)
}

# Funci贸n para calcular el gradiente
gradient <- function(X, y, beta) {
  return(t(X) %*% (X %*% beta - y))
}
```

## Ejemplo

```{r}
# Algoritmo de Newton
newton_method <- function(X, y, tol = 1e-6, max_iter = 100) {
  # Inicializar los coeficientes beta
  beta = matrix(0, ncol = 1, nrow = ncol(X))
  
  # Iteraciones
  for (i in 1:max_iter) {
    # Calcular gradiente y Hessiana
    grad = gradient(X, y, beta)
    hess = hessian(X, beta)
    
    # Actualizar beta usando el m茅todo de Newton
    beta_new = beta - solve(hess) %*% grad
    
    # Revisar la convergencia
    if (sum(abs(beta_new - beta)) < tol) {
      cat("Convergencia alcanzada en la iteraci贸n:", i, "\n")
      break
    }
    
    # Actualizar beta
    beta = beta_new
  }
  
  # Retornar los coeficientes estimados
  return(beta)
}
```

## Ejemplo

```{r}
# Ejecutar el algoritmo
coeficientes = newton_method(X, y)
```

## Ejemplo

```{r}
# Mostrar resultados
print("Coeficientes estimados:")
print(coeficientes)

```

# Estad铆stica

## Estad铆stica

Extensi贸n o aplicaci贸n real de lo que hab茅is visto en clase.

Hab茅is visto, por ejemplo, el uso del test Chi-cuadrado o el test T de student, y puede ser interesante ver c贸mo compaginar dichas pruebas estad铆sticas con gr谩ficos o con tests m谩s avanzados.

## Ejemplo

Determinar si existen diferencias significativas en el tama帽o del p茅talo entre las especies de flores (setosa, versicolor, virginica) usando:

- Test T de Student para comparar pares de especies.
- Test Chi-cuadrado para evaluar la relaci贸n entre especies y categor铆as de tama帽o del p茅talo.

## Ejemplo

```{r}
# Dividir las especies
setosa = iris[iris$Species == "setosa", ]
versicolor = iris[iris$Species == "versicolor", ]
virginica = iris[iris$Species == "virginica", ]

# Visualizar la distribuci贸n del tama帽o del p茅talo
library(ggplot2)
ggplot(iris, aes(x = Petal.Length, fill = Species)) +
  geom_histogram(bins = 20, alpha = 0.6, position = "identity") +
  labs(title = "Distribuci贸n del tama帽o del p茅talo por especie",
       x = "Tama帽o del p茅talo", y = "Frecuencia") +
  theme_minimal()
```

## Ejemplo

1. Test T de Student: Comparar especies de forma pareja
H0: No hay diferencia significativa en el tama帽o del p茅talo entre las especies.

```{r}
(t_test_setosa_versicolor = t.test(setosa$Petal.Length, versicolor$Petal.Length))
(t_test_versicolor_virginica = t.test(versicolor$Petal.Length, virginica$Petal.Length))
(t_test_setosa_virginica = t.test(setosa$Petal.Length, virginica$Petal.Length))
```

## Ejemplo

2. Test Chi-cuadrado: Relaci贸n entre especies y categor铆as de tama帽o del p茅talo
Crear categor铆as del tama帽o del p茅talo

```{r}
iris$Petal.Size.Category = cut(iris$Petal.Length,
                               breaks = c(0, 2, 4, 6, Inf),
                               labels = c("Peque帽o", "Mediano", "Grande", "Muy grande"))

# Tabla de contingencia
tabla_contingencia = table(iris$Species, iris$Petal.Size.Category)
```

## Ejemplo

```{r}
# Realizar test Chi-cuadrado
chi_test = chisq.test(tabla_contingencia)

# Mostrar resultados
cat("\nTabla de contingencia:\n")
print(tabla_contingencia)
chi_test
```

## Ejemplo

3. Visualizar la relaci贸n entre las categor铆as de tama帽o y las especies

```{r, eval=FALSE}
ggplot(iris, aes(x = Species, fill = Petal.Size.Category)) +
  geom_bar(position = "fill") +
  labs(title = "Proporci贸n de categor铆as de tama帽o del p茅talo por especie",
       x = "Especie", y = "Proporci贸n") +
  theme_minimal()
```

## Ejemplo

```{r, echo=FALSE}
ggplot(iris, aes(x = Species, fill = Petal.Size.Category)) +
  geom_bar(position = "fill") +
  labs(title = "Proporci贸n de categor铆as de tama帽o del p茅talo por especie",
       x = "Especie", y = "Proporci贸n") +
  theme_minimal()
```

# Machine learning

## Machine learning

 **Nuevo**, aunque realmente estaba dentro del proyecto:

- *B煤squeda en rejilla*.
- *Introducci贸n al machine learning*.

## Ejemplo

Usaremos ML para predecir la especie a partir de las otras variables:

## Cargar librer铆as y datos

```{r}
# Cargar librer铆as necesarias
library(randomForest)
library(caret)  # Para particionar datos y evaluaci贸n de modelos
library(pROC)   # Para la curva ROC
library(nnet)   # Para regresi贸n log铆stica multinomial

# Cargar el conjunto de datos
data(iris)

# Dividir los datos en entrenamiento (70%) y prueba (30%)
set.seed(123)
train_index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[train_index, ]
test_data <- iris[-train_index, ]
```

## Modelo Random Forest

```{r}
# Entrenar el modelo Random Forest
rf_model <- randomForest(Species ~ ., data = train_data, importance = TRUE, ntree = 100)

# Predicciones en el conjunto de prueba
rf_predictions <- predict(rf_model, test_data)

# Evaluar el modelo Random Forest
confusion_rf <- confusionMatrix(rf_predictions, test_data$Species)
cat("Matriz de Confusi贸n para Random Forest:\n")
print(confusion_rf)

# Importancia de las variables
cat("\nImportancia de las variables (Random Forest):\n")
print(importance(rf_model))
```

## Modelo log铆stico

```{r}
# Entrenar el modelo log铆stico multinomial
logistic_model <- multinom(Species ~ ., data = train_data)

# Predicciones en el conjunto de prueba
logistic_predictions <- predict(logistic_model, test_data)

# Evaluar el modelo log铆stico
confusion_logistic <- confusionMatrix(logistic_predictions, test_data$Species)
cat("\nMatriz de Confusi贸n para el Modelo Log铆stico:\n")
print(confusion_logistic)
```

## Curvas ROC

```{r}
# Curva ROC para Random Forest y Regresi贸n Log铆stica
rf_prob <- predict(rf_model, test_data, type = "prob")
logistic_prob <- predict(logistic_model, test_data, type = "probs")

# Calcular las curvas ROC para cada especie (multiclase)
cat("\nCurvas ROC para Random Forest y Regresi贸n Log铆stica:\n")
for (i in levels(test_data$Species)) {
  # Random Forest
  roc_rf <- roc(ifelse(test_data$Species == i, 1, 0), rf_prob[, i], levels = c(0, 1), direction = "<")
  auc_rf <- auc(roc_rf)
  cat("AUC para Random Forest (especie:", i, "):", auc_rf, "\n")
  
  # Modelo Log铆stico
  roc_log <- roc(ifelse(test_data$Species == i, 1, 0), logistic_prob[, i], levels = c(0, 1), direction = "<")
  auc_log <- auc(roc_log)
  cat("AUC para Modelo Log铆stico (especie:", i, "):", auc_log, "\n")
}
```

## Otros resultados

```{r}
# Cargar librer铆as necesarias
library(randomForest)
library(caret)
library(ggplot2)

# Cargar los datos y dividirlos en entrenamiento y prueba
data(iris)
set.seed(123)
train_index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train_data <- iris[train_index, ]
test_data <- iris[-train_index, ]
```

## Otros resultados

```{r}
# Entrenar el modelo Random Forest
rf_model <- randomForest(Species ~ ., data = train_data, importance = TRUE, ntree = 100)

# Predicciones en el conjunto de prueba
rf_predictions <- predict(rf_model, test_data)
```

## Otros resultados - Matriz de confusi贸n

```{r}
# ----------------------------
# 1. Visualizaci贸n: Matriz de Confusi贸n
# ----------------------------
# Crear la matriz de confusi贸n
confusion_rf <- confusionMatrix(rf_predictions, test_data$Species)

# Extraer datos para un gr谩fico de calor
confusion_matrix <- as.data.frame(confusion_rf$table)
colnames(confusion_matrix) <- c("Predicci贸n", "Real", "Frecuencia")
```

## Otros resultados - Matriz de confusi贸n

```{r, eval = FALSE}
# Visualizar la matriz de confusi贸n con ggplot2
ggplot(confusion_matrix, aes(x = Real, y = Predicci贸n, fill = Frecuencia)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(
    title = "Matriz de Confusi贸n - Random Forest",
    x = "Etiqueta Real",
    y = "Etiqueta Predicha"
  ) +
  theme_minimal()
```

## Otros resultados - Matriz de confusi贸n

```{r, echo = FALSE}
# Visualizar la matriz de confusi贸n con ggplot2
ggplot(confusion_matrix, aes(x = Real, y = Predicci贸n, fill = Frecuencia)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(
    title = "Matriz de Confusi贸n - Random Forest",
    x = "Etiqueta Real",
    y = "Etiqueta Predicha"
  ) +
  theme_minimal()
```

## Otros resultados - Error de clasificaci贸n

```{r}
# Extraer los errores del modelo Random Forest
error_df <- data.frame(
  rbol = 1:length(rf_model$err.rate[, "OOB"]),
  Error = rf_model$err.rate[, "OOB"]
)
```

```{r eval = FALSE}
# Visualizar el error fuera de bolsa (OOB) con ggplot2
ggplot(error_df, aes(x = rbol, y = Error)) +
  geom_line(color = "red", size = 1) +
  labs(
    title = "Error de Clasificaci贸n vs N煤mero de rboles",
    x = "N煤mero de rboles",
    y = "Error de Clasificaci贸n (OOB)"
  ) +
  theme_minimal()
```

## Otros resultados - Error de clasificaci贸n

```{r echo=FALSE}
# Visualizar el error fuera de bolsa (OOB) con ggplot2
ggplot(error_df, aes(x = rbol, y = Error)) +
  geom_line(color = "red", size = 1) +
  labs(
    title = "Error de Clasificaci贸n vs N煤mero de rboles",
    x = "N煤mero de rboles",
    y = "Error de Clasificaci贸n (OOB)"
  ) +
  theme_minimal()

```

# Resumen

## Resumen

**驴Qu茅 quer茅is?**